# airflow-values.yaml

# Set the executor to KubernetesExecutor
# This will cause Airflow to spin up a new pod for each task instance.
executor: KubernetesExecutor

env:
  - name: "AIRFLOW_CONN_KUBERNETES_DEFAULT"
    value: "kubernetes://"
  - name: "AIRFLOW_CONN_KAFKA_DEFAULT"
    value: "kafka://:@192.168.0.187:9092"

# Generate your own secret keys for production.
# Fernet Key: python -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
# Webserver Key: openssl rand -hex 30
# These are my locals but you won't be getting any access to anything with these :wink:
webserverSecretKey: "a745947747baf7bd0410bd526c88b3f1dc03a6b95cd1700baa992f73ed7f"
fernetKey: "Y1ToX3X8nztBJA56w9z5oCA1YImEn9PcR-vE3FZRIqU="

# Use git-sync to fetch DAGs from a remote repository.
# This is highly recommended for KubernetesExecutor.
dags:
  persistence:
    # We disable the PVC for dags because git-sync will handle them.
    enabled: false
  # gitSync:
  #   enabled: true
  #   # Replace this with the URL to YOUR git repository containing your DAGs.
  #   repo: "https://github.com/wesh92/public-airflow-examples.git"
  #   branch: "main"
  #   # Optional: if your DAGs are in a subdirectory of the repo.
  #   subPath: "dags"
  #   # For a private repo, you would configure credentials here using a secret.
  #   # sshKeySecret: my-ssh-key-secret
  gitSync:
    enabled: true
    repo: "https://github.com/wesh92/public-airflow-examples.git"
    branch: "feature/kafka-consumer-dag" # Changed from "main"
    subPath: "dags"
images:
  airflow:
    # Use the name you gave your local image
    repository: my-local-airflow
    tag: latest
    # This is the key: it tells Kubernetes to use the local
    # image if present and not try to pull it from the internet.
    pullPolicy: IfNotPresent

connections:
  - conn_id: "kubernetes_default"
    conn_type: "kubernetes"
    conn_extra: "{}"
  - conn_id: "kafka_default"
    conn_type: "kafka"
    conn_extra: |
      {"bootstrap.servers": "192.168.0.187:9092"}

# It's good practice to set resource requests and limits for a real deployment
# but we'll use the defaults for this guide.
